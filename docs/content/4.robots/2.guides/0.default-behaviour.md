---
title: Default Behavior
description: Learn how the nuxt-simple-robots module works out of the box.
---

By default, the module will either use a server middleware to generate a `robots.txt` at runtime
or generate a `robots.txt` file in the public directory when prerendering.

You can view this file at `/robots.txt` in your browser.

```bash
/public
└── robots.txt
```

## Non-production Environments

A non-production environment is any environment that has `process.env.NODE_ENV !== 'production'`.

For non-production environments, the module will generate a `robots.txt` file that disallows all bots.

``` [robots.txt blocking all bots]
User-agent: *
Disallow: /
```

You can manually opt-in to the mode
by providing `indexable: false` for your [Site Config](https://github.com/harlan-zw/nuxt-site-config).

## Production Environments

A production environment is any environment that has `process.env.NODE_ENV === 'production'`.

For production environments, the module will generate a `robots.txt` file that allows all bots.

``` [robots.txt allowing all bots]
User-agent: *
Disallow: 
```

You can manually opt-in to the mode
by providing `indexable: true` for your [Site Config](https://github.com/harlan-zw/nuxt-site-config).


## Sitemaps

The module integrates without any configuration with the [nuxt-simple-sitemap](/sitemap) module.
