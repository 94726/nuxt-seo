---
title: Default Behavior
description: Learn how the nuxt-simple-robots module works out of the box.
---

By default, the module will either use a server middleware to generate a `robots.txt` at runtime
or generate a `robots.txt` file in the public directory when prerendering.

You can view this file at `/robots.txt` in your browser.

```bash
/public
└── robots.txt
```

## Non-production Environments

For non-production environments, the module will generate a `robots.txt` file that disallows all bots.

``` [robots.txt blocking all bots]
User-agent: *
Disallow: /
```

## Production Environments

For production environments, the module will generate a `robots.txt` file that allows all bots.

``` [robots.txt allowing all bots]
User-agent: *
Disallow: 
```

## Sitemaps

The module integrates without any configuration with the [nuxt-simple-sitemap](/sitemap) module.
